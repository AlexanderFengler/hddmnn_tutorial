{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 0.0: COLAB PREP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'gdrive/My Drive/hddmnn_tutorial'\n",
      "/Users/afengler/OneDrive/git_repos/hddmnn_tutorial\n",
      "Found existing installation: tensorflow 1.15.0\n",
      "Uninstalling tensorflow-1.15.0:\n",
      "  Would remove:\n",
      "    /Users/afengler/opt/miniconda3/envs/hddm_dev/bin/estimator_ckpt_converter\n",
      "    /Users/afengler/opt/miniconda3/envs/hddm_dev/bin/freeze_graph\n",
      "    /Users/afengler/opt/miniconda3/envs/hddm_dev/bin/saved_model_cli\n",
      "    /Users/afengler/opt/miniconda3/envs/hddm_dev/bin/tensorboard\n",
      "    /Users/afengler/opt/miniconda3/envs/hddm_dev/bin/tf_upgrade_v2\n",
      "    /Users/afengler/opt/miniconda3/envs/hddm_dev/bin/tflite_convert\n",
      "    /Users/afengler/opt/miniconda3/envs/hddm_dev/bin/toco\n",
      "    /Users/afengler/opt/miniconda3/envs/hddm_dev/bin/toco_from_protos\n",
      "    /Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages/tensorflow-1.15.0.dist-info/*\n",
      "    /Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages/tensorflow/*\n",
      "    /Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages/tensorflow_core/*\n",
      "Proceed (y/n)? ^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 2347, in _normalize_cached\n",
      "    return _cache[filename]\n",
      "KeyError: '/Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python37.zip'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/afengler/opt/miniconda3/envs/hddm_dev/bin/pip\", line 7, in <module>\n",
      "    from pip._internal.cli.main import main\n",
      "  File \"/Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages/pip/_internal/cli/main.py\", line 10, in <module>\n",
      "    from pip._internal.cli.autocompletion import autocomplete\n",
      "  File \"/Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages/pip/_internal/cli/autocompletion.py\", line 9, in <module>\n",
      "    from pip._internal.cli.main_parser import create_main_parser\n",
      "  File \"/Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages/pip/_internal/cli/main_parser.py\", line 7, in <module>\n",
      "    from pip._internal.cli import cmdoptions\n",
      "  File \"/Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages/pip/_internal/cli/cmdoptions.py\", line 23, in <module>\n",
      "    from pip._internal.cli.progress_bars import BAR_TYPES\n",
      "  File \"/Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages/pip/_internal/cli/progress_bars.py\", line 12, in <module>\n",
      "    from pip._internal.utils.logging import get_indentation\n",
      "  File \"/Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages/pip/_internal/utils/logging.py\", line 18, in <module>\n",
      "    from pip._internal.utils.misc import ensure_dir\n",
      "  File \"/Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages/pip/_internal/utils/misc.py\", line 21, in <module>\n",
      "    from pip._vendor import pkg_resources\n",
      "  File \"/Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 3251, in <module>\n",
      "    @_call_aside\n",
      "  File \"/Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 3235, in _call_aside\n",
      "    f(*args, **kwargs)\n",
      "  File \"/Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 3279, in _initialize_master_working_set\n",
      "    for dist in working_set\n",
      "  File \"/Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 3279, in <genexpr>\n",
      "    for dist in working_set\n",
      "  File \"/Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 2780, in activate\n",
      "    self.insert_on(path, replace=replace)\n",
      "  File \"/Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 2896, in insert_on\n",
      "    npath = [(p and _normalize_cached(p) or p) for p in path]\n",
      "  File \"/Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 2896, in <listcomp>\n",
      "    npath = [(p and _normalize_cached(p) or p) for p in path]\n",
      "  File \"/Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 2349, in _normalize_cached\n",
      "    _cache[filename] = result = normalize_path(filename)\n",
      "  File \"/Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 2331, in normalize_path\n",
      "    return os.path.normcase(os.path.realpath(os.path.normpath(_cygwin_patch(filename))))\n",
      "  File \"/Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n",
      "Requirement already satisfied: pymc in /Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages (2.3.8)\n",
      "Requirement already satisfied: kabuki in /Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages (0.6.3)\n",
      "Requirement already satisfied: pymc>=2.3.6 in /Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages (from kabuki) (2.3.8)\n",
      "Requirement already satisfied: NumPy>=1.6.0 in /Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages (from kabuki) (1.19.2)\n",
      "Requirement already satisfied: matplotlib>=1.0.0 in /Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages (from kabuki) (3.3.2)\n",
      "Requirement already satisfied: pandas>=0.12.0 in /Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages (from kabuki) (1.1.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages (from matplotlib>=1.0.0->kabuki) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages (from matplotlib>=1.0.0->kabuki) (1.2.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages (from matplotlib>=1.0.0->kabuki) (2020.6.20)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages (from matplotlib>=1.0.0->kabuki) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages (from matplotlib>=1.0.0->kabuki) (8.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages (from matplotlib>=1.0.0->kabuki) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages (from pandas>=0.12.0->kabuki) (2020.1)\n",
      "Requirement already satisfied: six in /Users/afengler/opt/miniconda3/envs/hddm_dev/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=1.0.0->kabuki) (1.15.0)\n",
      "Collecting git+https://github.com/alexanderfengler/hddm@nn_likelihood\n",
      "  Cloning https://github.com/alexanderfengler/hddm (to revision nn_likelihood) to /private/var/folders/gx/s43vynx550qbypcxm83fv56dzq4hgg/T/pip-req-build-sw6nl3p0\n",
      "Building wheels for collected packages: HDDM\n",
      "  Building wheel for HDDM (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for HDDM: filename=HDDM-0.7.5-cp37-cp37m-macosx_10_9_x86_64.whl size=386055 sha256=09282cf88b1d9f97b6a5888c06463d7636cc22c0232a912ff622eeae291253d0\n",
      "  Stored in directory: /private/var/folders/gx/s43vynx550qbypcxm83fv56dzq4hgg/T/pip-ephem-wheel-cache-5mseb9xz/wheels/c2/3c/65/36b417d0a8864bd935e44a8b071470148147c2d7ea0314d2ee\n",
      "Successfully built HDDM\n",
      "Installing collected packages: HDDM\n",
      "  Attempting uninstall: HDDM\n",
      "    Found existing installation: HDDM 0.7.5\n",
      "    Uninstalling HDDM-0.7.5:\n",
      "      Successfully uninstalled HDDM-0.7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed HDDM-0.7.5\r\n"
     ]
    }
   ],
   "source": [
    "# %cd gdrive/'My Drive'/hddmnn_tutorial\n",
    "\n",
    "# !pip uninstall tensorflow  # tf 2.3.0 is loaded by default --> very slow on our networks\n",
    "# !pip install tensorflow-gpu==1.15 # tf 1.15 ~ 4 times faster (feel free to test this out)\n",
    "# !pip install pymc\n",
    "# !pip install kabuki\n",
    "# !pip install -U --no-deps git+https://github.com/alexanderfengler/hddm@nn_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODULE IMPORTS ----\n",
    "\n",
    "# \n",
    "import hddm\n",
    "\n",
    "# Make simulators visible\n",
    "import sys\n",
    "sys.path.append('simulators')\n",
    "\n",
    "# Data management\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "# Stats functionality\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "\n",
    "# CUSTOM IMPORTS (LOCAL FILES) --------\n",
    "import cddm_data_simulation as cds\n",
    "import boundary_functions as bf\n",
    "\n",
    "from helper_functions import simulator\n",
    "from helper_functions import simulator_covariate\n",
    "from helper_functions import simulator_stimcoding\n",
    "from helper_functions import model_plot\n",
    "from helper_functions import caterpillar_plot\n",
    "from helper_functions import posterior_pair_plot\n",
    "# from helper_functions import hddm_preprocess_hierarchical\n",
    "from helper_functions import simulator_condition_effects\n",
    "from helper_functions import make_parameter_sets\n",
    "from helper_functions import _make_trace_plotready_condition\n",
    "from helper_functions import hddm_preprocess\n",
    "from helper_functions import simulator_hierarchical\n",
    "from helper_functions import posterior_predictive_plot\n",
    "# --------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_outlier = []\n",
    "include_conf = {'angle': ['z', 'theta'] + p_outlier,\n",
    "                'weibull_cdf':['z', 'alpha', 'beta'] + p_outlier,\n",
    "                'full_ddm': ['z', 'st', 'sv', 'sz'] + p_outlier,\n",
    "                'levy': ['z', 'alpha'] + p_outlier,\n",
    "                'ornstein': ['z', 'g'] + p_outlier,\n",
    "                'ddm_sdv': ['z', 'sv'] + p_outlier,\n",
    "                'ddm': ['z']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'ornstein'\n",
    "n_samples = 10000\n",
    "p_outlier = [] # ['p_outlier']\n",
    "\n",
    "\n",
    "params = make_parameter_sets(model = model,\n",
    "                             n_parameter_sets = 1)\n",
    "\n",
    "simulations = simulator(theta = params.values[0],\n",
    "                        model = model,\n",
    "                        n_samples = n_samples)\n",
    "\n",
    "hddm_data_single_subject = hddm_preprocess(simulations)\n",
    "\n",
    "\n",
    "\n",
    "# hddm_model_ddm_analytic_single_subject = hddm.HDDMnn(hddm_data_ddm_single_subject, \n",
    "#                                                          model = 'ddm_analytic',\n",
    "#                                                          informative = False,\n",
    "#                                                          include = ['z'],\n",
    "#                                                          is_group_model = False)\n",
    "\n",
    "# Defining a hddm model\n",
    "hddm_model_single_subject = hddm.HDDMnn(hddm_data_single_subject,\n",
    "                                        model = model,\n",
    "                                        informative = False,\n",
    "                                        include = include_conf[model],\n",
    "                                        p_outlier = 0.0,\n",
    "                                        w_outlier = 0.01,\n",
    "                                        is_group_model = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmcmc = 300\n",
    "hddm_model_single_subject.sample(nmcmc, \n",
    "                                     burn = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('dic: ', hddm_model_single_subject.dic)\n",
    "print(hddm_model_single_subject.gen_stats()['mean'])\n",
    "print('gt params: ', params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_predictive_plot(posterior_samples = hddm_model_single_subject.get_traces(), #hddm_model_weibull_single_subject.get_traces(),\n",
    "                          ground_truths_parameters = params.values[0], #weibull_params.values[0],\n",
    "                          ground_truths_data = np.concatenate([simulations[0], simulations[1]], axis = 1), # None\n",
    "                          n_plots = 1,\n",
    "                          cols = 1,\n",
    "                          model_fitted = model,\n",
    "                          model_gt = None, #'levy', #'weibull_cdf',\n",
    "                          datatype = 'single_subject',\n",
    "                          n_post_params = 200,\n",
    "                          samples_by_param = 100,\n",
    "                          xlimit = 10,\n",
    "                          bin_size = 0.025,\n",
    "                          hist_linewidth = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caterpillar Plot: (Parameters recovered ok?)\n",
    "caterpillar_plot(posterior_samples = hddm_model_single_subject.get_traces(),\n",
    "                 ground_truths = params.values[0], #weibull_params.values[0],\n",
    "                 model = model,\n",
    "                 datatype = 'single_subject',\n",
    "                 drop_sd = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONDITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'ornstein'\n",
    "n_samples_by_condition = 500\n",
    "p_outlier = [] # ['p_outlier']\n",
    "\n",
    "\n",
    "hddm_data_condition, gt_condition, gt_mat_condition = simulator_condition_effects(n_conditions = 4,\n",
    "                                                                                  n_samples_by_condition = n_samples_by_condition,\n",
    "                                                                                  condition_effect_on_param = ['v', 'a'],\n",
    "                                                                                  model = model)\n",
    "\n",
    "\n",
    "hddm_model_condition = hddm.HDDMnn(hddm_data_condition, \n",
    "                                   model = model,\n",
    "                                   informative = False,\n",
    "                                   include = include_conf[model],\n",
    "                                   p_outlier = 0.,\n",
    "                                   w_outlier = 0.,\n",
    "                                   is_group_model = False, \n",
    "                                   depends_on = {'v': 'condition', 'a': 'condition'})\n",
    "\n",
    "\n",
    "hddm_model_condition.sample(500, burn = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caterpillar Plot: (Parameters recovered ok?)\n",
    "caterpillar_plot(posterior_samples = hddm_model_condition.get_traces(),\n",
    "                 ground_truths = gt_condition, #weibull_params.values[0],\n",
    "                 model = model,\n",
    "                 datatype = 'condition',\n",
    "                 drop_sd = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GROUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'simulator_hierarchical' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-349617700efd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Simulate data angle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m hddm_data_hierarchical, gt_hierarchical, gt_mat_hierarchical = simulator_hierarchical(n_subjects = n_subjects,\n\u001b[0m\u001b[1;32m      9\u001b[0m                                                                                       \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                                                                       n_samples_by_subject = n_samples_by_subject)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'simulator_hierarchical' is not defined"
     ]
    }
   ],
   "source": [
    "model = 'angle'\n",
    "n_subjects = 10\n",
    "n_samples_by_subject = 500\n",
    "p_outlier = [] # ['p_outlier']\n",
    "\n",
    "\n",
    "# Simulate data angle\n",
    "hddm_data_hierarchical, gt_hierarchical, gt_mat_hierarchical = simulator_hierarchical(n_subjects = n_subjects,\n",
    "                                                                                      model = model,\n",
    "                                                                                      n_samples_by_subject = n_samples_by_subject)\n",
    "\n",
    "\n",
    "hddm_hierarchical_model = hddm.HDDMnn(hddm_data_hierarchical, \n",
    "                                                    model = model,\n",
    "                                                    informative = False,\n",
    "                                                    include = include_conf[model],\n",
    "                                                    p_outlier = 0,\n",
    "                                                    w_outlier = 0,\n",
    "                                                    is_group_model = True)\n",
    "\n",
    "# # Sampling:\n",
    "nmcmc = 500\n",
    "hddm_hierarchical_model.sample(nmcmc,\n",
    "                               burn = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset data?\n",
    "hddm_data_hierarchical_limited = hddm_data_hierarchical.iloc[:2500]\n",
    "str_allowed = ['005', \n",
    "               '006', \n",
    "               '007', \n",
    "               '008', \n",
    "               '009', \n",
    "               '010', \n",
    "               '011', \n",
    "               '012', \n",
    "               '013', \n",
    "               '014', \n",
    "               '015', \n",
    "               '016',\n",
    "               '017',\n",
    "               '018',\n",
    "               '019']\n",
    "gt_hierarchical_limited = (gt_hierarchical).copy()\n",
    "for str_tmp in gt_hierarchical.keys():\n",
    "    for str_allowed_tmp in str_allowed:\n",
    "        if str_allowed_tmp in str_tmp:\n",
    "            gt_hierarchical_limited.pop(str_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caterpillar Plot\n",
    "caterpillar_plot(posterior_samples = hddm_hierarchical_model.get_traces(),\n",
    "                 ground_truths = gt_hierarchical,\n",
    "                 model = model,\n",
    "                 datatype = 'hierarchical',\n",
    "                 x_lims = [-2, 2],\n",
    "                 aspect_ratio = 2,\n",
    "                 drop_sd = False,\n",
    "                 save = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ornstein params\n",
    "model = 'ddm'\n",
    "n_samples = 1000\n",
    "\n",
    "params =  make_parameter_sets(model = model,\n",
    "                              n_parameter_sets = 1)\n",
    "\n",
    "simulations = simulator(theta = params.values[0],\n",
    "                        model = model, \n",
    "                        n_samples = n_samples)\n",
    "\n",
    "hddm_data_single_subject_regress = hddm_preprocess(simulations)\n",
    "\n",
    "# Add a regressor:\n",
    "hddm_data_single_subject_regress['BOLD'] = np.random.uniform(low = - 1, high = 1, size = n_samples)\n",
    "\n",
    "#v_reg = {'model': 'v ~ 1 + BOLD', 'link_func': lambda x: x}\n",
    "#a_reg = {'model': 'a ~ 1 + BOLD', 'link_func': lambda x: x}\n",
    "#t_reg = {'model': 't ~ 1 + BOLD', 'link_func': lambda x: x}\n",
    "g_reg = {'model': 'a ~ 1 + BOLD', 'link_func': lambda x: x}\n",
    "\n",
    "reg_descr = [g_reg] #[v_reg, a_reg, t_reg, g_reg] # theta_reg]\n",
    "\n",
    "hddm_reg = hddm.HDDMnnRegressor(hddm_data_single_subject_regress, \n",
    "                                reg_descr, \n",
    "                                include = set(include_conf[model]),\n",
    "                                model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sampling:\n",
    "nmcmc = 500\n",
    "hddm_reg.sample(nmcmc,\n",
    "                burn = 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
