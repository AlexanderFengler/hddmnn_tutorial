{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use your Custom LAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have your own LAN, or really, a class with a `predict_on_batch()` method which you can call to get back the log-likelihood of a dataset, you can pass it as an argument to the `HDDMnn`, `HDDMnnRegressor` or `HDDMnnStimCoding` classes. \n",
    "\n",
    "In this document we provide you with a simple complete example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such a new model will be called `custom`, for our purposes. Let's say we trained a LAN for it. \n",
    "\n",
    "We need two components to use our `custom` LAN. \n",
    "\n",
    "1. A config dictionary for the `custom` model.\n",
    "2. A pretrained LAN with a `predict_on_batch` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONSTRUCT THE CONFIG DICTIONARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hddm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the config dictionary for all models included in `HDDM` by calling the  `hddm.model_config.model_config` dictionary.\n",
    "Learn more about this object in **lan tutorial concerning new models**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hddm.model_config.model_config[\"custom\"] =  {\n",
    "        \"params\": [\"v\", \"a\", \"z\", \"t\"], # parameter names associated to your model \n",
    "        \"params_trans\": [0, 0, 1, 0], # for each parameter do you want the sampler to transform it into an unconstrained space? (invlogit <--> logistic)\n",
    "        \"params_std_upper\": [1.5, 1.0, None, 1.0], # for group models, what is the maximal standard deviation to consider for the prior on the parameter\n",
    "        \"param_bounds\": [[-3.0, 0.3, 0.1, 1e-3], [3.0, 2.5, 0.9, 2.0]], # the parameter boundaries you used for training your LAN\n",
    "        \"boundary\": hddm.simulators.bf.constant, # add a boundary function (if relevant to your model) (optional)\n",
    "        \"n_params\": 4, # number of parameters of your model\n",
    "        \"default_params\": [0.0, 1.0, 0.5, 1e-3], # defaults for each parameter \n",
    "        \"hddm_include\": [\"z\"], # suggestion for which parameters to include via the include statement of an HDDM model (usually you want all of the parameters from above)\n",
    "        \"n_choices\": 2, # number of choice options of the model\n",
    "        \"choices\": [-1, 1], # choice labels (what your simulator spits out)\n",
    "        \"slice_widths\": {\"v\": 1.5, \"v_std\": 1,  \n",
    "                         \"a\": 1, \"a_std\": 1, \n",
    "                         \"z\": 0.1, \"z_trans\": 0.2, \n",
    "                         \"t\": 0.01, \"t_std\": 0.15}, # hyperparameters for the slice-sampler used for posterior sampling, take these as an orientation, can be helpful to optimize speed (optional)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD THE NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the example complete, here is a code snippet to load in a `Keras` model. We are simply using the `ddm` network here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_network = hddm.torch.mlp_inference_class.load_torch_mlp(model = 'ddm')  # or any class with a valid predict on batch function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate some data:\n",
    "model = 'ddm'\n",
    "n_subjects = 1\n",
    "n_samples_by_subject = 500\n",
    "\n",
    "data, full_parameter_dict = hddm.simulators.hddm_dataset_generators.simulator_h_c(n_subjects = n_subjects,\n",
    "                                                                                  n_samples_by_subject = n_samples_by_subject,\n",
    "                                                                                  model = model,\n",
    "                                                                                  p_outlier = 0.00,\n",
    "                                                                                  conditions = None, \n",
    "                                                                                  depends_on = None, \n",
    "                                                                                  regression_models = None,\n",
    "                                                                                  regression_covariates = None,\n",
    "                                                                                  group_only_regressors = False,\n",
    "                                                                                  group_only = None,\n",
    "                                                                                  fixed_at_default = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INITIALIZE THE HDDM MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to load a HDDM model with your `custom` LAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting priors uninformative (LANs only work with uninformative priors for now)\n",
      "Includes supplied:  ['z']\n"
     ]
    }
   ],
   "source": [
    "# Define the HDDM model\n",
    "hddmnn_model = hddm.HDDMnn(data = data,\n",
    "                           informative = False,\n",
    "                           include = hddm.model_config.model_config['custom']['hddm_include'], # Note: This include statement is an example, you may pick any other subset of the parameters of your model here\n",
    "                           model = 'custom',\n",
    "                           network_type = 'torch_mlp',\n",
    "                           network = custom_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are now ready to get samples from your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [-----------------100%-----------------] 1000 of 1000 complete in 23.1 sec"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pymc.MCMC.MCMC at 0x7fc56d733a50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hddmnn_model.sample(1000, burn = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all the functionality of the HDDM package will work seamlessly with such custom likelihoods. \n",
    "You will be able to generate some, but not all plots.\n",
    "\n",
    "The utility lies in using HDDM as a vehicle to sample from user defined approximate likelihoods.\n",
    "Most of the packages utility functions have a higher degree of specificity to models that have been fully incorporated into the package.\n",
    "\n",
    "Look at the tutorial `add_new_models_to_hddm_tutorial.ipynb` for a higher degree of integration."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "560f708a8e3e7d8a6040d2821b64a1d977dd58637277f7fff51c695b3b27a4a1"
  },
  "kernelspec": {
   "display_name": "hddm-gpu",
   "language": "python",
   "name": "hddm-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
